import pandas as pd
import numpy as np
from dotenv import load_dotenv
import os
import sqlite3
import gradio as gr

from langchain_community.document_loaders import TextLoader
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_core.documents import Document
from scipy.sparse import csr_matrix
from sklearn.neighbors import NearestNeighbors

# --- C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N (FIX L·ªñI WINDOWS/ONEDRIVE) ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
def get_abs_path(filename):
    return os.path.join(BASE_DIR, filename)

# --- 1. DATABASE L·ªäCH S·ª¨ ---
def init_db():
    try:
        conn = sqlite3.connect(get_abs_path('user_history.db'))
        c = conn.cursor()
        # T·∫°o b·∫£ng c√≥ th√™m c·ªôt top_book
        c.execute('''CREATE TABLE IF NOT EXISTS search_history 
                     (id INTEGER PRIMARY KEY, user_id TEXT, query TEXT, top_book TEXT, timestamp DATETIME DEFAULT CURRENT_TIMESTAMP)''')
        conn.commit()
        conn.close()
    except: pass

def log_search(user_id, query, top_book_title):
    try:
        conn = sqlite3.connect(get_abs_path('user_history.db'))
        c = conn.cursor()
        if query.strip():
            # L∆∞u c·∫£ query v√† t√™n s√°ch Top 1
            c.execute("INSERT INTO search_history (user_id, query, top_book) VALUES (?, ?, ?)", 
                      (user_id, query, top_book_title))
            conn.commit()
        conn.close()
    except Exception as e: print(f"L·ªói log: {e}")

def get_recent_interests(user_id, current_query="", limit=3):
    # H√†m n√†y gi·ªØ nguy√™n ƒë·ªÉ ph·ª•c v·ª• g·ª£i √Ω
    try:
        conn = sqlite3.connect(get_abs_path('user_history.db'))
        c = conn.cursor()
        c.execute("SELECT DISTINCT query FROM search_history WHERE user_id = ? AND query != ? ORDER BY id DESC LIMIT ?", (user_id, current_query, limit))
        rows = c.fetchall()
        conn.close()
        return [row[0] for row in rows]
    except: return []

def get_history_logs(user_id="guest", limit=10):
    """H√†m l·∫•y l·ªãch s·ª≠ S√ÅCH TOP 1 ƒë·ªÉ hi·ªÉn th·ªã"""
    try:
        conn = sqlite3.connect(get_abs_path('user_history.db'))
        c = conn.cursor()
        # L·∫•y th·ªùi gian v√† T√™n s√°ch (top_book) thay v√¨ query
        c.execute("SELECT strftime('%Y-%m-%d %H:%M:%S', timestamp), top_book FROM search_history WHERE user_id = ? ORDER BY id DESC LIMIT ?", (user_id, limit))
        rows = c.fetchall()
        conn.close()
        return rows 
    except: return []

# --- 2. H·ªÜ TH·ªêNG COLLABORATIVE FILTERING ---
cf_model = None
book_pivot = None
book_index_map = None 

def init_collaborative_filtering():
    global cf_model, book_pivot, book_index_map
    print("üîÑ ƒêang kh·ªüi t·∫°o Collaborative Filtering...")
    ratings_path = get_abs_path("ratings.csv")
    
    if not os.path.exists(ratings_path):
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y ratings.csv -> B·ªè qua CF.")
        return

    try:
        # √âp ki·ªÉu d·ªØ li·ªáu isbn th√†nh string ngay t·ª´ ƒë·∫ßu
        df_ratings = pd.read_csv(ratings_path, dtype={'isbn': str, 'user_id': str})
        
        # X·ª≠ l√Ω s·∫°ch ISBN (b·ªè .0 n·∫øu c√≥)
        df_ratings['isbn'] = df_ratings['isbn'].astype(str).str.replace(r'\.0$', '', regex=True).str.strip()
        
        book_pivot = df_ratings.pivot_table(index='isbn', columns='user_id', values='rating').fillna(0)
        book_index_map = {isbn: i for i, isbn in enumerate(book_pivot.index)}
        book_sparse = csr_matrix(book_pivot.values)
        cf_model = NearestNeighbors(metric='cosine', algorithm='brute')
        cf_model.fit(book_sparse)
        print(f"‚úÖ CF Model OK! ({len(book_pivot)} s√°ch trong h·ªá th·ªëng g·ª£i √Ω)")
    except Exception as e:
        print(f"‚ùå L·ªói kh·ªüi t·∫°o CF: {e}")

def get_collaborative_recs(isbn, n_neighbors=6):
    if cf_model is None or book_index_map is None: return []
    
    # Chu·∫©n h√≥a input ISBN
    isbn = str(isbn).replace(".0", "").strip()
    
    if isbn not in book_index_map:
        # print(f"DEBUG: ISBN {isbn} kh√¥ng c√≥ trong d·ªØ li·ªáu ratings")
        return []
    try:
        query_index = book_index_map[isbn]
        distances, indices = cf_model.kneighbors(book_pivot.iloc[query_index, :].values.reshape(1, -1), n_neighbors=n_neighbors)
        
        recs = []
        for i in range(1, len(distances.flatten())):
            idx = indices.flatten()[i]
            recs.append(book_pivot.index[idx])
        return recs
    except: return []

# --- 3. KH·ªûI ƒê·ªòNG ---
print("üöÄ ƒêang kh·ªüi ƒë·ªông ·ª©ng d·ª•ng...")
init_db()
init_collaborative_filtering()
load_dotenv()

# LOAD S√ÅCH (C·ª∞C K·ª≤ QUAN TR·ªåNG: √âP KI·ªÇU STRING)
csv_path = get_abs_path("books_with_emotions.csv")
if not os.path.exists(csv_path): csv_path = get_abs_path("books_cleaned.csv")

try:
    # dtype={'isbn13': str} l√† ch√¨a kh√≥a ƒë·ªÉ s·ª≠a l·ªói t√¨m ki·∫øm
    books = pd.read_csv(csv_path, dtype={'isbn13': str})
    
    # Chu·∫©n h√≥a c·ªôt ISBN m·ªôt l·∫ßn n·ªØa cho ch·∫Øc ch·∫Øn
    if "isbn13" in books.columns:
        books["isbn13"] = books["isbn13"].astype(str).str.replace(r'\.0$', '', regex=True).str.strip()
    
    if "large_thumbnail" not in books.columns:
        books["large_thumbnail"] = books["thumbnail"]
        
    print(f"‚úÖ ƒê√£ load {len(books)} cu·ªën s√°ch v√†o b·ªô nh·ªõ.")
except Exception as e:
    print(f"‚ùå L·ªñI KH√îNG ƒê·ªåC ƒê∆Ø·ª¢C FILE S√ÅCH: {e}")
    exit()

# LOAD VECTOR DB
embedding_model = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
PERSIST_DIR = get_abs_path("chroma_db")
db_books = None

if os.path.exists(PERSIST_DIR):
    try:
        db_books = Chroma(persist_directory=PERSIST_DIR, embedding_function=embedding_model)
        # Test connection
        db_books.similarity_search("test", k=1)
        print("‚úÖ K·∫øt n·ªëi ChromaDB th√†nh c√¥ng!")
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói k·∫øt n·ªëi DB: {e}")
        # Fallback RAM mode...
else:
    print("‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c chroma_db. H√£y ch·∫°y reset_all_data.py tr∆∞·ªõc!")

# --- 4. LOGIC T√åM KI·∫æM (C√ì DEBUG LOG) ---
def retrieve_semantic_recommendations(query, category="All", tone="All", top_k=100):
    if not db_books: return pd.DataFrame()
    
    print(f"\nüîé [DEBUG] ƒêang t√¨m ki·∫øm: '{query}'")
    
    # 1. T√¨m trong Vector DB
    try:
        recs = db_books.similarity_search(query, k=top_k)
        print(f"   -> T√¨m th·∫•y {len(recs)} vector t∆∞∆°ng ƒë·ªìng.")
    except Exception as e:
        print(f"   -> L·ªói vector search: {e}")
        return pd.DataFrame()

    # 2. Tr√≠ch xu·∫•t ISBN
    isbn_list = []
    for i, rec in enumerate(recs):
        # ∆Øu ti√™n l·∫•y t·ª´ metadata (do reset_all_data.py t·∫°o ra)
        val = rec.metadata.get("isbn")
        
        # N·∫øu kh√¥ng c√≥ metadata, th·ª≠ l·∫•y t·ª´ n·ªôi dung (fallback c≈©)
        if not val:
            content_parts = rec.page_content.split()
            if content_parts: val = content_parts[0]
            
        # L√†m s·∫°ch chu·ªói ISBN
        if val:
            val = str(val).replace(".0", "").strip()
            if val.isdigit(): 
                isbn_list.append(val)
    
    # In ra v√†i ISBN ƒë·∫ßu ti√™n ƒë·ªÉ ki·ªÉm tra
    if isbn_list:
        print(f"   -> Tr√≠ch xu·∫•t ƒë∆∞·ª£c {len(isbn_list)} ISBN h·ª£p l·ªá. V√≠ d·ª•: {isbn_list[:3]}")
    else:
        print("   -> ‚ö†Ô∏è C·∫¢NH B√ÅO: Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c ISBN n√†o t·ª´ k·∫øt qu·∫£ vector!")
        return pd.DataFrame()

    # 3. ƒê·ªëi chi·∫øu v·ªõi DataFrame Books
    # L·ªçc nh·ªØng ISBN c√≥ t·ªìn t·∫°i trong file CSV
    book_recs = books[books["isbn13"].isin(isbn_list)].copy()
    print(f"   -> Kh·ªõp ƒë∆∞·ª£c {len(book_recs)} cu·ªën s√°ch trong file CSV.")

    # S·∫Øp x·∫øp theo ƒë√∫ng th·ª© t·ª± t√¨m ki·∫øm (quan tr·ªçng)
    if not book_recs.empty:
        book_recs = book_recs.set_index("isbn13")
        # Ch·ªâ gi·ªØ l·∫°i nh·ªØng isbn c√≥ trong list t√¨m ki·∫øm v√† s·∫Øp x·∫øp theo th·ª© t·ª± ƒë√≥
        valid_isbns = [i for i in isbn_list if i in book_recs.index]
        book_recs = book_recs.reindex(valid_isbns).reset_index()

    # 4. L·ªçc Category
    if category != "All" and "simple_categories" in book_recs.columns:
        original_count = len(book_recs)
        book_recs = book_recs[book_recs["simple_categories"] == category]
        print(f"   -> Sau khi l·ªçc Category '{category}': c√≤n {len(book_recs)}/{original_count} cu·ªën.")

    # 5. L·ªçc Tone
    if tone != "All":
        tone_map = {"Happy": "joy", "Surprising": "surprise", "Angry": "anger", "Suspenseful": "fear", "Sad": "sadness"}
        col = tone_map.get(tone)
        if col and col in book_recs.columns:
            book_recs = book_recs.sort_values(by=col, ascending=False)
            print(f"   -> ƒê√£ s·∫Øp x·∫øp l·∫°i theo c·∫£m x√∫c '{tone}'.")

    return book_recs

def format_results(df):
    results = []
    if df.empty: return results
    for _, row in df.iterrows():
        title = str(row['title'])
        authors = str(row['authors']) if pd.notna(row['authors']) else "Unknown"
        # X·ª≠ l√Ω m√¥ t·∫£ ng·∫Øn
        desc = str(row.get('description', ''))
        trunc_desc = " ".join(desc.split()[:20]) + "..."
        
        caption = f"{title}\nby {authors}\n\n{trunc_desc}"
        img = row["large_thumbnail"] if pd.notna(row["large_thumbnail"]) else "cover-not-found.jpg"
        results.append((img, caption))
    return results

def recommend_books(query, category, tone):
    # 1. Content-Based Search (T√¨m ki·∫øm n·ªôi dung tr∆∞·ªõc)
    content_df = retrieve_semantic_recommendations(query, category, tone)
    current_results = format_results(content_df)
    
    top_book_log = "Kh√¥ng t√¨m th·∫•y"
    if not content_df.empty:
        # L·∫•y ti√™u ƒë·ªÅ cu·ªën s√°ch ƒë·∫ßu ti√™n t√¨m th·∫•y
        top_book_log = str(content_df.iloc[0]['title'])
    
    user_id = "guest"
    # G·ªçi h√†m log v·ªõi ƒê·ª¶ 3 THAM S·ªê
    log_search(user_id, query, top_book_log)

    # 2. Collaborative Filtering (G·ª£i √Ω t·ª´ c·ªông ƒë·ªìng)
    secondary_results = []
    msg = ""
    
    if not content_df.empty:
        top_isbn = str(content_df.iloc[0]['isbn13'])
        top_title = str(content_df.iloc[0]['title'])
        
        print(f"üîó [CF] ƒêang t√¨m s√°ch li√™n quan ƒë·∫øn: {top_title} ({top_isbn})")
        cf_isbns = get_collaborative_recs(top_isbn)
        
        if cf_isbns:
            cf_df = books[books['isbn13'].isin(cf_isbns)]
            if not cf_df.empty:
                secondary_results = format_results(cf_df)
                msg = f"V√¨ b·∫°n quan t√¢m '{top_title}' (C·ªông ƒë·ªìng c≈©ng ƒë·ªçc)"

    # 3. Fallback History / Random (N·∫øu kh√¥ng t√¨m th·∫•y g√¨)
    if not secondary_results:
        print("‚ö†Ô∏è Fallback: D√πng l·ªãch s·ª≠ ho·∫∑c Random.")
        
        recent = get_recent_interests(user_id, query)
        if recent:
            hist_query = " ".join(recent)
            hist_df = retrieve_semantic_recommendations(hist_query, top_k=50)
            if not hist_df.empty:
                secondary_results = format_results(hist_df.sample(frac=1).head(8))
                msg = "D·ª±a tr√™n l·ªãch s·ª≠ t√¨m ki·∫øm g·∫ßn ƒë√¢y"
    
    if not secondary_results:
         secondary_results = format_results(books.sample(8))
         msg = "C√≥ th·ªÉ b·∫°n s·∫Ω th√≠ch (Ng·∫´u nhi√™n)"

    # 4. L·∫•y l·∫°i l·ªãch s·ª≠ m·ªõi nh·∫•t ƒë·ªÉ c·∫≠p nh·∫≠t UI
    updated_history = get_history_logs(user_id)

    return current_results, secondary_results, msg, updated_history

# --- 5. UI ---
categories = ["All"]
if "simple_categories" in books.columns:
    categories += sorted(books["simple_categories"].dropna().unique().tolist())

with gr.Blocks(theme=gr.themes.Glass()) as dashboard:
    gr.Markdown("# AI Book Recommender (Hybrid System)")
    gr.Markdown("T√¨m ki·∫øm th√¥ng minh + G·ª£i √Ω c·ªông ƒë·ªìng")
    
    with gr.Row():
        with gr.Column(scale=1):
            inp = gr.Textbox(label="B·∫°n mu·ªën t√¨m s√°ch g√¨?", placeholder="V√≠ d·ª•: Harry Potter, magic, history...")
            cat = gr.Dropdown(categories, label="Th·ªÉ lo·∫°i", value="All")
            tone = gr.Dropdown(["All", "Happy", "Sad", "Suspenseful", "Surprising", "Angry"], label="C·∫£m x√∫c", value="All")
            btn = gr.Button("T√¨m ki·∫øm", variant="primary")
            
            # --- M·ªöI: B·∫£ng hi·ªÉn th·ªã l·ªãch s·ª≠ ---
            gr.Markdown("### S√°ch v·ª´a t√¨m ƒë∆∞·ª£c")
            history_table = gr.Dataframe(
                headers=["Th·ªùi gian", "S√°ch Top 1 ƒê·ªÅ xu·∫•t"],  # ƒê·ªïi t√™n c·ªôt
                datatype=["str", "str"],
                value=get_history_logs(), 
                interactive=False
            )
            
        with gr.Column(scale=3):
            out1 = gr.Gallery(label="K·∫øt qu·∫£ t√¨m ki·∫øm", columns=5, height=450, object_fit="contain")
            lbl = gr.Markdown("### G·ª£i √Ω b·ªï sung")
            out2 = gr.Gallery(label="G·ª£i √Ω b·ªï sung", columns=5, height=300, object_fit="contain")

    # C·∫≠p nh·∫≠t s·ª± ki·ªán click: Th√™m history_table v√†o danh s√°ch outputs
    btn.click(recommend_books, [inp, cat, tone], [out1, out2, lbl, history_table])

if __name__ == "__main__":
    print("üåê App ƒëang ch·∫°y t·∫°i: http://127.0.0.1:7860")
    dashboard.launch()